{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       11145\n",
      "unique         24\n",
      "top       2017-18\n",
      "freq          540\n",
      "Name: data_pts, dtype: object\n",
      "count    11076.000000\n",
      "mean         1.373781\n",
      "std          0.591478\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max          4.000000\n",
      "Name: data_age, dtype: float64\n",
      "193.04\n",
      "<class 'pandas.core.frame.DataFrame'> 44560 (8912, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> 17824 (8912, 2)\n",
      "<class 'pandas.core.frame.DataFrame'> 11145 (2229, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> 4458 (2229, 2)\n",
      "<class 'pandas.core.frame.DataFrame'> 44560 (8912, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> 17824 (8912, 2)\n",
      "<class 'pandas.core.frame.DataFrame'> 11145 (2229, 5)\n",
      "<class 'pandas.core.frame.DataFrame'> 4458 (2229, 2)\n",
      "<class 'numpy.ndarray'> 44560 (8912, 5)\n",
      "<class 'numpy.ndarray'> 17824 (8912, 2)\n",
      "<class 'numpy.ndarray'> 11145 (2229, 5)\n",
      "<class 'numpy.ndarray'> 4458 (2229, 2)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 27)                162       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                364       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                168       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 720\n",
      "Trainable params: 720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "298/298 [==============================] - 12s 747us/step - loss: -388.0617 - accuracy: 0.7612\n",
      "Epoch 2/300\n",
      "298/298 [==============================] - 0s 755us/step - loss: -42740.7404 - accuracy: 0.7700\n",
      "Epoch 3/300\n",
      "298/298 [==============================] - 0s 756us/step - loss: -429349.3238 - accuracy: 0.7627\n",
      "Epoch 4/300\n",
      "298/298 [==============================] - 0s 769us/step - loss: -1717665.9925 - accuracy: 0.7621\n",
      "Epoch 5/300\n",
      "298/298 [==============================] - 0s 810us/step - loss: -4670657.4674 - accuracy: 0.7632\n",
      "Epoch 6/300\n",
      "298/298 [==============================] - 0s 984us/step - loss: -9940176.4281 - accuracy: 0.7588\n",
      "Epoch 7/300\n",
      "298/298 [==============================] - 0s 970us/step - loss: -18200144.0468 - accuracy: 0.7724\n",
      "Epoch 8/300\n",
      "298/298 [==============================] - 0s 870us/step - loss: -30293215.5987 - accuracy: 0.7567\n",
      "Epoch 9/300\n",
      "298/298 [==============================] - 0s 940us/step - loss: -47138883.2642 - accuracy: 0.7594\n",
      "Epoch 10/300\n",
      "298/298 [==============================] - 0s 774us/step - loss: -68523557.1906 - accuracy: 0.7573\n",
      "Epoch 11/300\n",
      "298/298 [==============================] - 0s 754us/step - loss: -96206568.9097 - accuracy: 0.7599\n",
      "Epoch 12/300\n",
      "298/298 [==============================] - 0s 837us/step - loss: -129468125.8863 - accuracy: 0.7667\n",
      "Epoch 13/300\n",
      "298/298 [==============================] - 0s 815us/step - loss: -169002658.0334 - accuracy: 0.7563\n",
      "Epoch 14/300\n",
      "298/298 [==============================] - 0s 768us/step - loss: -221091572.4415 - accuracy: 0.7609\n",
      "Epoch 15/300\n",
      "298/298 [==============================] - 0s 837us/step - loss: -279330045.4314 - accuracy: 0.7624\n",
      "Epoch 16/300\n",
      "298/298 [==============================] - 0s 801us/step - loss: -345589564.6823 - accuracy: 0.7579\n",
      "Epoch 17/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -421202291.6923 - accuracy: 0.7567\n",
      "Epoch 18/300\n",
      "298/298 [==============================] - 0s 833us/step - loss: -504229525.6187 - accuracy: 0.7575\n",
      "Epoch 19/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -604532799.1438 - accuracy: 0.7611\n",
      "Epoch 20/300\n",
      "298/298 [==============================] - 0s 766us/step - loss: -713489533.6455 - accuracy: 0.7659\n",
      "Epoch 21/300\n",
      "298/298 [==============================] - 0s 738us/step - loss: -842183100.1472 - accuracy: 0.7638\n",
      "Epoch 22/300\n",
      "298/298 [==============================] - 0s 742us/step - loss: -977236025.1505 - accuracy: 0.7676\n",
      "Epoch 23/300\n",
      "298/298 [==============================] - 0s 739us/step - loss: -1122300010.1672 - accuracy: 0.7589\n",
      "Epoch 24/300\n",
      "298/298 [==============================] - 0s 738us/step - loss: -1286399309.0569 - accuracy: 0.7643\n",
      "Epoch 25/300\n",
      "298/298 [==============================] - 0s 757us/step - loss: -1448971309.8060 - accuracy: 0.7551\n",
      "Epoch 26/300\n",
      "298/298 [==============================] - 0s 749us/step - loss: -1655443868.2542 - accuracy: 0.7593\n",
      "Epoch 27/300\n",
      "298/298 [==============================] - 0s 748us/step - loss: -1863405112.0803 - accuracy: 0.7646\n",
      "Epoch 28/300\n",
      "298/298 [==============================] - 0s 753us/step - loss: -2108639049.2040 - accuracy: 0.7611\n",
      "Epoch 29/300\n",
      "298/298 [==============================] - 0s 751us/step - loss: -2356327787.8796 - accuracy: 0.7615\n",
      "Epoch 30/300\n",
      "298/298 [==============================] - 0s 762us/step - loss: -2652647207.3846 - accuracy: 0.7702\n",
      "Epoch 31/300\n",
      "298/298 [==============================] - 0s 743us/step - loss: -2910752046.2341 - accuracy: 0.7592\n",
      "Epoch 32/300\n",
      "298/298 [==============================] - 0s 732us/step - loss: -3243817375.2508 - accuracy: 0.7643\n",
      "Epoch 33/300\n",
      "298/298 [==============================] - 0s 726us/step - loss: -3555654772.4415 - accuracy: 0.7545\n",
      "Epoch 34/300\n",
      "298/298 [==============================] - 0s 745us/step - loss: -3949724963.1037 - accuracy: 0.7666\n",
      "Epoch 35/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -4269082133.4047 - accuracy: 0.7545\n",
      "Epoch 36/300\n",
      "298/298 [==============================] - 0s 762us/step - loss: -4729758197.7258 - accuracy: 0.7627\n",
      "Epoch 37/300\n",
      "298/298 [==============================] - 0s 736us/step - loss: -5147020382.1806 - accuracy: 0.7672\n",
      "Epoch 38/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -5573356276.8696 - accuracy: 0.7556\n",
      "Epoch 39/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -6105245148.0401 - accuracy: 0.7616\n",
      "Epoch 40/300\n",
      "298/298 [==============================] - 0s 738us/step - loss: -6563791687.0635 - accuracy: 0.7590\n",
      "Epoch 41/300\n",
      "298/298 [==============================] - 0s 754us/step - loss: -7140228219.2910 - accuracy: 0.7568\n",
      "Epoch 42/300\n",
      "298/298 [==============================] - 0s 748us/step - loss: -7736657550.1271 - accuracy: 0.7646\n",
      "Epoch 43/300\n",
      "298/298 [==============================] - 0s 737us/step - loss: -8386133132.4147 - accuracy: 0.7665\n",
      "Epoch 44/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -8994245741.5920 - accuracy: 0.7655\n",
      "Epoch 45/300\n",
      "298/298 [==============================] - 0s 737us/step - loss: -9687530972.0401 - accuracy: 0.7624\n",
      "Epoch 46/300\n",
      "298/298 [==============================] - 0s 733us/step - loss: -10401034370.1405 - accuracy: 0.7646\n",
      "Epoch 47/300\n",
      "298/298 [==============================] - 0s 731us/step - loss: -11088421751.0100 - accuracy: 0.7569\n",
      "Epoch 48/300\n",
      "298/298 [==============================] - 0s 723us/step - loss: -11914320687.0903 - accuracy: 0.7559\n",
      "Epoch 49/300\n",
      "298/298 [==============================] - 0s 729us/step - loss: -12735706649.6856 - accuracy: 0.7593\n",
      "Epoch 50/300\n",
      "298/298 [==============================] - 0s 736us/step - loss: -13668748712.6689 - accuracy: 0.7621\n",
      "Epoch 51/300\n",
      "298/298 [==============================] - 0s 732us/step - loss: -14600515131.9331 - accuracy: 0.7608\n",
      "Epoch 52/300\n",
      "298/298 [==============================] - 0s 733us/step - loss: -15466741208.6154 - accuracy: 0.7614\n",
      "Epoch 53/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -16435070184.8829 - accuracy: 0.7609\n",
      "Epoch 54/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -17629771454.0736 - accuracy: 0.7626\n",
      "Epoch 55/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -18704499441.4448 - accuracy: 0.7543\n",
      "Epoch 56/300\n",
      "298/298 [==============================] - 0s 736us/step - loss: -19811872877.5920 - accuracy: 0.7584\n",
      "Epoch 57/300\n",
      "298/298 [==============================] - 0s 740us/step - loss: -20993852056.4013 - accuracy: 0.7617\n",
      "Epoch 58/300\n",
      "298/298 [==============================] - 0s 736us/step - loss: -21947492153.3645 - accuracy: 0.7545\n",
      "Epoch 59/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -23569530469.0301 - accuracy: 0.7668\n",
      "Epoch 60/300\n",
      "298/298 [==============================] - 0s 739us/step - loss: -24700385122.4615 - accuracy: 0.7619\n",
      "Epoch 61/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -26303665765.0301 - accuracy: 0.7644\n",
      "Epoch 62/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -27822665508.8161 - accuracy: 0.7635\n",
      "Epoch 63/300\n",
      "298/298 [==============================] - 0s 810us/step - loss: -29513205246.2876 - accuracy: 0.7641\n",
      "Epoch 64/300\n",
      "298/298 [==============================] - 0s 731us/step - loss: -30662475488.3211 - accuracy: 0.7687\n",
      "Epoch 65/300\n",
      "298/298 [==============================] - 0s 797us/step - loss: -32071949842.8361 - accuracy: 0.7612\n",
      "Epoch 66/300\n",
      "298/298 [==============================] - 0s 740us/step - loss: -33947490810.8629 - accuracy: 0.7589\n",
      "Epoch 67/300\n",
      "298/298 [==============================] - 0s 733us/step - loss: -35640201969.4448 - accuracy: 0.7626\n",
      "Epoch 68/300\n",
      "298/298 [==============================] - 0s 738us/step - loss: -37393683356.6823 - accuracy: 0.7579\n",
      "Epoch 69/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -39262975883.5585 - accuracy: 0.7622\n",
      "Epoch 70/300\n",
      "298/298 [==============================] - 0s 735us/step - loss: -41182047392.9632 - accuracy: 0.7608\n",
      "Epoch 71/300\n",
      "298/298 [==============================] - 0s 741us/step - loss: -43156941546.5953 - accuracy: 0.7635\n",
      "Epoch 72/300\n",
      "298/298 [==============================] - 0s 743us/step - loss: -45503727595.4515 - accuracy: 0.7603\n",
      "Epoch 73/300\n",
      "298/298 [==============================] - 0s 737us/step - loss: -47828931409.3378 - accuracy: 0.7611\n",
      "Epoch 74/300\n",
      "298/298 [==============================] - 0s 736us/step - loss: -49903997119.7859 - accuracy: 0.7616\n",
      "Epoch 75/300\n",
      "298/298 [==============================] - 0s 734us/step - loss: -52002369289.4181 - accuracy: 0.7678\n",
      "Epoch 76/300\n",
      "298/298 [==============================] - 0s 731us/step - loss: -54716698473.3110 - accuracy: 0.7664\n",
      "Epoch 77/300\n",
      "298/298 [==============================] - 0s 742us/step - loss: -57044125949.4314 - accuracy: 0.7636\n",
      "Epoch 78/300\n",
      "298/298 [==============================] - 0s 779us/step - loss: -59834863985.8729 - accuracy: 0.7692\n",
      "Epoch 79/300\n",
      "298/298 [==============================] - 0s 806us/step - loss: -62294538178.3545 - accuracy: 0.7586\n",
      "Epoch 80/300\n",
      "298/298 [==============================] - 0s 857us/step - loss: -64669246960.5886 - accuracy: 0.7620\n",
      "Epoch 81/300\n",
      "298/298 [==============================] - 0s 754us/step - loss: -67728103704.8294 - accuracy: 0.7645\n",
      "Epoch 82/300\n",
      "298/298 [==============================] - 0s 910us/step - loss: -70417528263.4916 - accuracy: 0.7567\n",
      "Epoch 83/300\n",
      "298/298 [==============================] - 0s 812us/step - loss: -73177678700.7358 - accuracy: 0.7639\n",
      "Epoch 84/300\n",
      "298/298 [==============================] - 0s 882us/step - loss: -76577462141.8595 - accuracy: 0.7584\n",
      "Epoch 85/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: -79812224263.7057 - accuracy: 0.7622\n",
      "Epoch 86/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: -84135592182.5819 - accuracy: 0.7689\n",
      "Epoch 87/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: -85483640633.3645 - accuracy: 0.7584\n",
      "Epoch 88/300\n",
      "298/298 [==============================] - 0s 874us/step - loss: -89987826348.9498 - accuracy: 0.7632\n",
      "Epoch 89/300\n",
      "298/298 [==============================] - 0s 863us/step - loss: -92255524446.1806 - accuracy: 0.7573\n",
      "Epoch 90/300\n",
      "298/298 [==============================] - 0s 851us/step - loss: -96976481139.5853 - accuracy: 0.7641\n",
      "Epoch 91/300\n",
      "298/298 [==============================] - 0s 831us/step - loss: -99827931101.7525 - accuracy: 0.7631\n",
      "Epoch 92/300\n",
      "298/298 [==============================] - 0s 1ms/step - loss: -103869938835.2642 - accuracy: 0.7716\n",
      "Epoch 93/300\n",
      "298/298 [==============================] - 0s 804us/step - loss: -107841336350.8227 - accuracy: 0.7581\n",
      "Epoch 94/300\n",
      "298/298 [==============================] - 0s 838us/step - loss: -111769306430.5017 - accuracy: 0.7651\n",
      "Epoch 95/300\n",
      "298/298 [==============================] - 0s 871us/step - loss: -115761550010.6488 - accuracy: 0.7585\n",
      "Epoch 96/300\n",
      "298/298 [==============================] - 0s 852us/step - loss: -120193903502.9833 - accuracy: 0.7599\n",
      "Epoch 97/300\n",
      "298/298 [==============================] - 0s 906us/step - loss: -124115762131.4783 - accuracy: 0.7554\n",
      "Epoch 98/300\n",
      "298/298 [==============================] - 0s 769us/step - loss: -129871372233.2040 - accuracy: 0.7642\n",
      "Epoch 99/300\n",
      "298/298 [==============================] - 0s 808us/step - loss: -133326007319.9733 - accuracy: 0.7611\n",
      "Epoch 100/300\n",
      "298/298 [==============================] - 0s 814us/step - loss: -138191586129.3378 - accuracy: 0.7585\n",
      "Epoch 101/300\n",
      "298/298 [==============================] - 0s 862us/step - loss: -141845712745.3110 - accuracy: 0.7613\n",
      "Epoch 102/300\n",
      "298/298 [==============================] - 0s 837us/step - loss: -149473931359.8930 - accuracy: 0.7581\n",
      "Epoch 103/300\n",
      "298/298 [==============================] - 0s 870us/step - loss: -153089252636.2542 - accuracy: 0.7606\n",
      "Epoch 104/300\n",
      "298/298 [==============================] - 0s 878us/step - loss: -158114470757.8863 - accuracy: 0.7629\n",
      "Epoch 105/300\n",
      "298/298 [==============================] - 0s 820us/step - loss: -163779263251.6923 - accuracy: 0.7609\n",
      "Epoch 106/300\n",
      "298/298 [==============================] - 0s 827us/step - loss: -169469368313.1505 - accuracy: 0.7594\n",
      "Epoch 107/300\n",
      "298/298 [==============================] - 0s 875us/step - loss: -174679512642.7826 - accuracy: 0.7554\n",
      "Epoch 108/300\n",
      "298/298 [==============================] - 0s 888us/step - loss: -180567674126.5552 - accuracy: 0.7645\n",
      "Epoch 109/300\n",
      "298/298 [==============================] - 0s 867us/step - loss: -187188740698.7559 - accuracy: 0.7616\n",
      "Epoch 110/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -190729367921.8729 - accuracy: 0.7600\n",
      "Epoch 111/300\n",
      "298/298 [==============================] - 0s 786us/step - loss: -197009486413.0569 - accuracy: 0.7498\n",
      "Epoch 112/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -205942950798.9833 - accuracy: 0.7665\n",
      "Epoch 113/300\n",
      "298/298 [==============================] - 0s 772us/step - loss: -211508525186.1405 - accuracy: 0.7627\n",
      "Epoch 114/300\n",
      "298/298 [==============================] - 0s 774us/step - loss: -216609981128.3478 - accuracy: 0.7635\n",
      "Epoch 115/300\n",
      "298/298 [==============================] - 0s 770us/step - loss: -222954882339.1037 - accuracy: 0.7574\n",
      "Epoch 116/300\n",
      "298/298 [==============================] - 0s 772us/step - loss: -229108553885.5385 - accuracy: 0.7596\n",
      "Epoch 117/300\n",
      "298/298 [==============================] - 0s 766us/step - loss: -236269821102.6622 - accuracy: 0.7573\n",
      "Epoch 118/300\n",
      "298/298 [==============================] - 0s 767us/step - loss: -247049706670.6622 - accuracy: 0.7605\n",
      "Epoch 119/300\n",
      "298/298 [==============================] - 0s 843us/step - loss: -251409616142.5552 - accuracy: 0.7593\n",
      "Epoch 120/300\n",
      "298/298 [==============================] - 0s 812us/step - loss: -259654608574.0736 - accuracy: 0.7692\n",
      "Epoch 121/300\n",
      "298/298 [==============================] - 0s 808us/step - loss: -265402793216.8562 - accuracy: 0.7541\n",
      "Epoch 122/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -275496762679.6522 - accuracy: 0.7724\n",
      "Epoch 123/300\n",
      "298/298 [==============================] - 0s 807us/step - loss: -282561105824.1070 - accuracy: 0.7633\n",
      "Epoch 124/300\n",
      "298/298 [==============================] - 0s 815us/step - loss: -291134407642.3278 - accuracy: 0.7716\n",
      "Epoch 125/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -301626121883.8261 - accuracy: 0.7595\n",
      "Epoch 126/300\n",
      "298/298 [==============================] - 0s 796us/step - loss: -306402736641.7124 - accuracy: 0.7574\n",
      "Epoch 127/300\n",
      "298/298 [==============================] - 0s 797us/step - loss: -314602112181.5117 - accuracy: 0.7618\n",
      "Epoch 128/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -324223073865.6321 - accuracy: 0.7596\n",
      "Epoch 129/300\n",
      "298/298 [==============================] - 0s 813us/step - loss: -334234876527.3043 - accuracy: 0.7607\n",
      "Epoch 130/300\n",
      "298/298 [==============================] - 0s 792us/step - loss: -342698547795.9064 - accuracy: 0.7650\n",
      "Epoch 131/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -356335244811.9866 - accuracy: 0.7645\n",
      "Epoch 132/300\n",
      "298/298 [==============================] - 0s 798us/step - loss: -361269511404.3077 - accuracy: 0.7577\n",
      "Epoch 133/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -372003234531.7458 - accuracy: 0.7643\n",
      "Epoch 134/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -383422898970.5418 - accuracy: 0.7663\n",
      "Epoch 135/300\n",
      "298/298 [==============================] - 0s 824us/step - loss: -391127618097.6589 - accuracy: 0.7575\n",
      "Epoch 136/300\n",
      "298/298 [==============================] - 0s 804us/step - loss: -399884308164.9231 - accuracy: 0.7622\n",
      "Epoch 137/300\n",
      "298/298 [==============================] - 0s 806us/step - loss: -412046985907.7993 - accuracy: 0.7650\n",
      "Epoch 138/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -418700977086.9297 - accuracy: 0.7575\n",
      "Epoch 139/300\n",
      "298/298 [==============================] - 0s 795us/step - loss: -436237556417.4984 - accuracy: 0.7625\n",
      "Epoch 140/300\n",
      "298/298 [==============================] - 0s 812us/step - loss: -446255395733.8328 - accuracy: 0.7680\n",
      "Epoch 141/300\n",
      "298/298 [==============================] - 0s 792us/step - loss: -454701259402.7023 - accuracy: 0.7603\n",
      "Epoch 142/300\n",
      "298/298 [==============================] - 0s 798us/step - loss: -466597273243.8261 - accuracy: 0.7673\n",
      "Epoch 143/300\n",
      "298/298 [==============================] - 0s 796us/step - loss: -479300801950.3947 - accuracy: 0.7681\n",
      "Epoch 144/300\n",
      "298/298 [==============================] - 0s 806us/step - loss: -492461777197.3779 - accuracy: 0.7641\n",
      "Epoch 145/300\n",
      "298/298 [==============================] - 0s 791us/step - loss: -500908199894.9030 - accuracy: 0.7579\n",
      "Epoch 146/300\n",
      "298/298 [==============================] - 0s 791us/step - loss: -512606973719.1171 - accuracy: 0.7616\n",
      "Epoch 147/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -524000110653.6455 - accuracy: 0.7583\n",
      "Epoch 148/300\n",
      "298/298 [==============================] - 0s 797us/step - loss: -534437564265.3110 - accuracy: 0.7641\n",
      "Epoch 149/300\n",
      "298/298 [==============================] - 0s 835us/step - loss: -557634902940.6823 - accuracy: 0.7655\n",
      "Epoch 150/300\n",
      "298/298 [==============================] - 0s 835us/step - loss: -568945226919.8127 - accuracy: 0.7643\n",
      "Epoch 151/300\n",
      "298/298 [==============================] - 0s 774us/step - loss: -582598912883.5853 - accuracy: 0.7616\n",
      "Epoch 152/300\n",
      "298/298 [==============================] - 0s 791us/step - loss: -591585128105.5250 - accuracy: 0.7642\n",
      "Epoch 153/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -608352525979.8260 - accuracy: 0.7636\n",
      "Epoch 154/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -617242855019.8796 - accuracy: 0.7546\n",
      "Epoch 155/300\n",
      "298/298 [==============================] - 0s 803us/step - loss: -637470274892.2007 - accuracy: 0.7655\n",
      "Epoch 156/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -647820342713.7926 - accuracy: 0.7634\n",
      "Epoch 157/300\n",
      "298/298 [==============================] - 0s 807us/step - loss: -662344228069.4583 - accuracy: 0.7517\n",
      "Epoch 158/300\n",
      "298/298 [==============================] - 0s 803us/step - loss: -688998082238.0736 - accuracy: 0.7691\n",
      "Epoch 159/300\n",
      "298/298 [==============================] - 0s 806us/step - loss: -696299356598.3679 - accuracy: 0.7616\n",
      "Epoch 160/300\n",
      "298/298 [==============================] - 0s 799us/step - loss: -710439013372.5752 - accuracy: 0.7591\n",
      "Epoch 161/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -730879000904.7759 - accuracy: 0.7591\n",
      "Epoch 162/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -741558207395.5317 - accuracy: 0.7631\n",
      "Epoch 163/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -762305536630.1538 - accuracy: 0.7576\n",
      "Epoch 164/300\n",
      "298/298 [==============================] - 0s 771us/step - loss: -786547779755.2374 - accuracy: 0.7743\n",
      "Epoch 165/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -788943599472.1605 - accuracy: 0.7640\n",
      "Epoch 166/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -814276106726.3143 - accuracy: 0.7615\n",
      "Epoch 167/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -830650115226.1138 - accuracy: 0.7661\n",
      "Epoch 168/300\n",
      "298/298 [==============================] - 0s 783us/step - loss: -840271518511.0903 - accuracy: 0.7599\n",
      "Epoch 169/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -858788435851.5585 - accuracy: 0.7603\n",
      "Epoch 170/300\n",
      "298/298 [==============================] - 0s 867us/step - loss: -883293017392.8027 - accuracy: 0.7623\n",
      "Epoch 171/300\n",
      "298/298 [==============================] - 0s 796us/step - loss: -905874031413.9398 - accuracy: 0.7599\n",
      "Epoch 172/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -923768194777.4716 - accuracy: 0.7593\n",
      "Epoch 173/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -935280682521.6857 - accuracy: 0.7624\n",
      "Epoch 174/300\n",
      "298/298 [==============================] - 0s 786us/step - loss: -958816770205.5385 - accuracy: 0.7646\n",
      "Epoch 175/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -985143003334.6355 - accuracy: 0.7658\n",
      "Epoch 176/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -998340490681.7926 - accuracy: 0.7604\n",
      "Epoch 177/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -1014357547384.7224 - accuracy: 0.7616\n",
      "Epoch 178/300\n",
      "298/298 [==============================] - 0s 798us/step - loss: -1046977565781.6188 - accuracy: 0.7610\n",
      "Epoch 179/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -1067567436118.4750 - accuracy: 0.7655\n",
      "Epoch 180/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -1080962869583.6254 - accuracy: 0.7595\n",
      "Epoch 181/300\n",
      "298/298 [==============================] - 0s 780us/step - loss: -1103493479626.0603 - accuracy: 0.7641\n",
      "Epoch 182/300\n",
      "298/298 [==============================] - 0s 785us/step - loss: -1128556119057.1238 - accuracy: 0.7671\n",
      "Epoch 183/300\n",
      "298/298 [==============================] - 0s 783us/step - loss: -1151561261028.6021 - accuracy: 0.7703\n",
      "Epoch 184/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -1166822149335.7593 - accuracy: 0.7605\n",
      "Epoch 185/300\n",
      "298/298 [==============================] - 0s 801us/step - loss: -1191967623859.7993 - accuracy: 0.7571\n",
      "Epoch 186/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -1216934847916.0938 - accuracy: 0.7627\n",
      "Epoch 187/300\n",
      "298/298 [==============================] - 0s 774us/step - loss: -1235550913772.3076 - accuracy: 0.7593\n",
      "Epoch 188/300\n",
      "298/298 [==============================] - 0s 779us/step - loss: -1259425721093.9934 - accuracy: 0.7650\n",
      "Epoch 189/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -1293331551865.5786 - accuracy: 0.7611\n",
      "Epoch 190/300\n",
      "298/298 [==============================] - 0s 895us/step - loss: -1317528400022.6890 - accuracy: 0.7623\n",
      "Epoch 191/300\n",
      "298/298 [==============================] - 0s 801us/step - loss: -1324417372940.8428 - accuracy: 0.7574\n",
      "Epoch 192/300\n",
      "298/298 [==============================] - 0s 766us/step - loss: -1362570477020.0400 - accuracy: 0.7657\n",
      "Epoch 193/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -1392936679499.3445 - accuracy: 0.7641\n",
      "Epoch 194/300\n",
      "298/298 [==============================] - 0s 803us/step - loss: -1414512981488.5886 - accuracy: 0.7610\n",
      "Epoch 195/300\n",
      "298/298 [==============================] - 0s 782us/step - loss: -1435941375520.5352 - accuracy: 0.7556\n",
      "Epoch 196/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -1461384833688.4014 - accuracy: 0.7636\n",
      "Epoch 197/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -1502138949385.4180 - accuracy: 0.7675\n",
      "Epoch 198/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -1513184033939.2642 - accuracy: 0.7624\n",
      "Epoch 199/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -1547794143499.1304 - accuracy: 0.7674\n",
      "Epoch 200/300\n",
      "298/298 [==============================] - 0s 814us/step - loss: -1564225081302.9031 - accuracy: 0.7638\n",
      "Epoch 201/300\n",
      "298/298 [==============================] - 0s 778us/step - loss: -1613354703060.3345 - accuracy: 0.7664\n",
      "Epoch 202/300\n",
      "298/298 [==============================] - 0s 785us/step - loss: -1628974712866.2476 - accuracy: 0.7606\n",
      "Epoch 203/300\n",
      "298/298 [==============================] - 0s 770us/step - loss: -1670806988258.8896 - accuracy: 0.7626\n",
      "Epoch 204/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -1684907300199.5986 - accuracy: 0.7608\n",
      "Epoch 205/300\n",
      "298/298 [==============================] - 0s 796us/step - loss: -1725676199853.8059 - accuracy: 0.7621\n",
      "Epoch 206/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -1752046909570.1404 - accuracy: 0.7619\n",
      "Epoch 207/300\n",
      "298/298 [==============================] - 0s 798us/step - loss: -1779340262711.6521 - accuracy: 0.7626\n",
      "Epoch 208/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -1805758791351.2241 - accuracy: 0.7660\n",
      "Epoch 209/300\n",
      "298/298 [==============================] - 0s 775us/step - loss: -1848244449266.3010 - accuracy: 0.7663\n",
      "Epoch 210/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -1877033120004.2810 - accuracy: 0.7601\n",
      "Epoch 211/300\n",
      "298/298 [==============================] - 0s 780us/step - loss: -1898367289487.8394 - accuracy: 0.7570\n",
      "Epoch 212/300\n",
      "298/298 [==============================] - 0s 799us/step - loss: -1957196784574.9297 - accuracy: 0.7746\n",
      "Epoch 213/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -1983701484944.6956 - accuracy: 0.7677\n",
      "Epoch 214/300\n",
      "298/298 [==============================] - 0s 774us/step - loss: -2021663790713.5786 - accuracy: 0.7610\n",
      "Epoch 215/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -2050036153107.6924 - accuracy: 0.7655\n",
      "Epoch 216/300\n",
      "298/298 [==============================] - 0s 803us/step - loss: -2096069675809.3914 - accuracy: 0.7612\n",
      "Epoch 217/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -2086086620327.8127 - accuracy: 0.7575\n",
      "Epoch 218/300\n",
      "298/298 [==============================] - 0s 780us/step - loss: -2140112963563.4514 - accuracy: 0.7571\n",
      "Epoch 219/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -2179732529234.1941 - accuracy: 0.7608\n",
      "Epoch 220/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -2216680940917.2979 - accuracy: 0.7658\n",
      "Epoch 221/300\n",
      "298/298 [==============================] - 0s 795us/step - loss: -2268532669477.6724 - accuracy: 0.7632\n",
      "Epoch 222/300\n",
      "298/298 [==============================] - 0s 786us/step - loss: -2273232816710.2075 - accuracy: 0.7587\n",
      "Epoch 223/300\n",
      "298/298 [==============================] - 0s 791us/step - loss: -2319070793138.9434 - accuracy: 0.7624\n",
      "Epoch 224/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -2363047444589.5918 - accuracy: 0.7653\n",
      "Epoch 225/300\n",
      "298/298 [==============================] - 0s 785us/step - loss: -2416350863935.3579 - accuracy: 0.7685\n",
      "Epoch 226/300\n",
      "298/298 [==============================] - 0s 773us/step - loss: -2436194634310.2075 - accuracy: 0.7565\n",
      "Epoch 227/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -2488624964214.1538 - accuracy: 0.7623\n",
      "Epoch 228/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -2545225076694.9028 - accuracy: 0.7586\n",
      "Epoch 229/300\n",
      "298/298 [==============================] - 0s 802us/step - loss: -2597591559191.9731 - accuracy: 0.7669\n",
      "Epoch 230/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -2617371185823.2510 - accuracy: 0.7567\n",
      "Epoch 231/300\n",
      "298/298 [==============================] - 0s 782us/step - loss: -2628934612793.3647 - accuracy: 0.7543\n",
      "Epoch 232/300\n",
      "298/298 [==============================] - 0s 769us/step - loss: -2708310464066.7827 - accuracy: 0.7618\n",
      "Epoch 233/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -2737348231222.7959 - accuracy: 0.7659\n",
      "Epoch 234/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -2739490170393.6855 - accuracy: 0.7618\n",
      "Epoch 235/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -2833015922660.6021 - accuracy: 0.7630\n",
      "Epoch 236/300\n",
      "298/298 [==============================] - 0s 804us/step - loss: -2879962805032.2407 - accuracy: 0.7638\n",
      "Epoch 237/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -2919966714136.8296 - accuracy: 0.7595\n",
      "Epoch 238/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -2932657285784.4014 - accuracy: 0.7649\n",
      "Epoch 239/300\n",
      "298/298 [==============================] - 0s 804us/step - loss: -2989468254098.4082 - accuracy: 0.7558\n",
      "Epoch 240/300\n",
      "298/298 [==============================] - 0s 770us/step - loss: -3042719079817.8462 - accuracy: 0.7654\n",
      "Epoch 241/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -3102048267397.5654 - accuracy: 0.7609\n",
      "Epoch 242/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -3132690457534.9297 - accuracy: 0.7586\n",
      "Epoch 243/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -3183485369217.2842 - accuracy: 0.7657\n",
      "Epoch 244/300\n",
      "298/298 [==============================] - 0s 827us/step - loss: -3232846867863.5449 - accuracy: 0.7617\n",
      "Epoch 245/300\n",
      "298/298 [==============================] - 0s 791us/step - loss: -3281435128506.6489 - accuracy: 0.7678\n",
      "Epoch 246/300\n",
      "298/298 [==============================] - 0s 820us/step - loss: -3306684000427.2373 - accuracy: 0.7604\n",
      "Epoch 247/300\n",
      "298/298 [==============================] - 0s 826us/step - loss: -3378457312732.0400 - accuracy: 0.7567\n",
      "Epoch 248/300\n",
      "298/298 [==============================] - 0s 889us/step - loss: -3453769320043.8794 - accuracy: 0.7661\n",
      "Epoch 249/300\n",
      "298/298 [==============================] - 0s 761us/step - loss: -3497102191420.7891 - accuracy: 0.7594\n",
      "Epoch 250/300\n",
      "298/298 [==============================] - 0s 826us/step - loss: -3495070116011.2373 - accuracy: 0.7622\n",
      "Epoch 251/300\n",
      "298/298 [==============================] - 0s 793us/step - loss: -3605685271480.0801 - accuracy: 0.7650\n",
      "Epoch 252/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -3597925118212.2808 - accuracy: 0.7570\n",
      "Epoch 253/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -3689131607111.9199 - accuracy: 0.7615\n",
      "Epoch 254/300\n",
      "298/298 [==============================] - 0s 772us/step - loss: -3756194868576.7490 - accuracy: 0.7659\n",
      "Epoch 255/300\n",
      "298/298 [==============================] - 0s 779us/step - loss: -3784509440931.5317 - accuracy: 0.7567\n",
      "Epoch 256/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -3819185713357.4849 - accuracy: 0.7662\n",
      "Epoch 257/300\n",
      "298/298 [==============================] - 0s 790us/step - loss: -3877019438679.3311 - accuracy: 0.7613\n",
      "Epoch 258/300\n",
      "298/298 [==============================] - 0s 805us/step - loss: -3944811009821.9668 - accuracy: 0.7563\n",
      "Epoch 259/300\n",
      "298/298 [==============================] - 0s 783us/step - loss: -4013028716639.8931 - accuracy: 0.7680\n",
      "Epoch 260/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -4089423644322.6758 - accuracy: 0.7675\n",
      "Epoch 261/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -4178703221393.5518 - accuracy: 0.7672\n",
      "Epoch 262/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -4187695033258.3813 - accuracy: 0.7643\n",
      "Epoch 263/300\n",
      "298/298 [==============================] - 0s 798us/step - loss: -4254748839127.7593 - accuracy: 0.7605\n",
      "Epoch 264/300\n",
      "298/298 [==============================] - 0s 777us/step - loss: -4300759142358.9028 - accuracy: 0.7615\n",
      "Epoch 265/300\n",
      "298/298 [==============================] - 0s 794us/step - loss: -4307374608342.9028 - accuracy: 0.7551\n",
      "Epoch 266/300\n",
      "298/298 [==============================] - 0s 782us/step - loss: -4495755104050.5146 - accuracy: 0.7719\n",
      "Epoch 267/300\n",
      "298/298 [==============================] - 0s 789us/step - loss: -4462479795792.4814 - accuracy: 0.7556\n",
      "Epoch 268/300\n",
      "298/298 [==============================] - 0s 783us/step - loss: -4565394352025.2578 - accuracy: 0.7613\n",
      "Epoch 269/300\n",
      "298/298 [==============================] - 0s 781us/step - loss: -4639877304826.8633 - accuracy: 0.7608\n",
      "Epoch 270/300\n",
      "298/298 [==============================] - 0s 780us/step - loss: -4657297210241.2842 - accuracy: 0.7597\n",
      "Epoch 271/300\n",
      "298/298 [==============================] - 0s 805us/step - loss: -4810749286064.3750 - accuracy: 0.7665\n",
      "Epoch 272/300\n",
      "298/298 [==============================] - 0s 784us/step - loss: -4832911248435.3711 - accuracy: 0.7662\n",
      "Epoch 273/300\n",
      "298/298 [==============================] - 0s 819us/step - loss: -4877008843834.2207 - accuracy: 0.7613\n",
      "Epoch 274/300\n",
      "298/298 [==============================] - 0s 766us/step - loss: -4983350203422.8223 - accuracy: 0.7630\n",
      "Epoch 275/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -5023312748133.0303 - accuracy: 0.7605\n",
      "Epoch 276/300\n",
      "298/298 [==============================] - 0s 788us/step - loss: -5083406656227.7461 - accuracy: 0.7685\n",
      "Epoch 277/300\n",
      "298/298 [==============================] - 0s 946us/step - loss: -5129279669648.6953 - accuracy: 0.7625\n",
      "Epoch 278/300\n",
      "298/298 [==============================] - 0s 924us/step - loss: -5184378587773.0029 - accuracy: 0.7555\n",
      "Epoch 279/300\n",
      "298/298 [==============================] - 0s 874us/step - loss: -5281466951522.4619 - accuracy: 0.7644\n",
      "Epoch 280/300\n",
      "298/298 [==============================] - 0s 941us/step - loss: -5321521257153.4980 - accuracy: 0.7655\n",
      "Epoch 281/300\n",
      "298/298 [==============================] - 0s 932us/step - loss: -5414978146208.1074 - accuracy: 0.7584\n",
      "Epoch 282/300\n",
      "298/298 [==============================] - 0s 921us/step - loss: -5478703136220.0400 - accuracy: 0.7643\n",
      "Epoch 283/300\n",
      "298/298 [==============================] - 0s 914us/step - loss: -5559112844853.0840 - accuracy: 0.7597\n",
      "Epoch 284/300\n",
      "298/298 [==============================] - 0s 859us/step - loss: -5632865891441.0166 - accuracy: 0.7642\n",
      "Epoch 285/300\n",
      "298/298 [==============================] - 0s 859us/step - loss: -5661726167820.8428 - accuracy: 0.7588\n",
      "Epoch 286/300\n",
      "298/298 [==============================] - 0s 787us/step - loss: -5785586779262.7158 - accuracy: 0.7584\n",
      "Epoch 287/300\n",
      "298/298 [==============================] - 0s 852us/step - loss: -5798691710270.5020 - accuracy: 0.7534\n",
      "Epoch 288/300\n",
      "298/298 [==============================] - 0s 780us/step - loss: -5892088581500.1475 - accuracy: 0.7603\n",
      "Epoch 289/300\n",
      "298/298 [==============================] - 0s 776us/step - loss: -6046118362204.4678 - accuracy: 0.7588\n",
      "Epoch 290/300\n",
      "298/298 [==============================] - 0s 845us/step - loss: -6084982528815.0898 - accuracy: 0.7623\n",
      "Epoch 291/300\n",
      "298/298 [==============================] - 0s 804us/step - loss: -6049588550830.6621 - accuracy: 0.7660\n",
      "Epoch 292/300\n",
      "298/298 [==============================] - 0s 822us/step - loss: -6215757883508.4414 - accuracy: 0.7575\n",
      "Epoch 293/300\n",
      "298/298 [==============================] - 0s 819us/step - loss: -6320893706842.7559 - accuracy: 0.7599\n",
      "Epoch 294/300\n",
      "298/298 [==============================] - 0s 852us/step - loss: -6396464338937.1504 - accuracy: 0.7586\n",
      "Epoch 295/300\n",
      "298/298 [==============================] - 0s 797us/step - loss: -6484190837304.5088 - accuracy: 0.7620\n",
      "Epoch 296/300\n",
      "298/298 [==============================] - 0s 801us/step - loss: -6580668156541.0029 - accuracy: 0.7606\n",
      "Epoch 297/300\n",
      "298/298 [==============================] - 0s 833us/step - loss: -6645750309000.9902 - accuracy: 0.7624\n",
      "Epoch 298/300\n",
      "298/298 [==============================] - 0s 847us/step - loss: -6661910792226.2471 - accuracy: 0.7611\n",
      "Epoch 299/300\n",
      "298/298 [==============================] - 0s 832us/step - loss: -6730227852496.9102 - accuracy: 0.7559\n",
      "Epoch 300/300\n",
      "298/298 [==============================] - 0s 836us/step - loss: -6882177942271.1436 - accuracy: 0.7684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 581us/step - loss: -7054378401792.0000 - accuracy: 0.7672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.767160177230835"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[153]:\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from csv import writer\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[155]:\n",
    "\n",
    "\n",
    "col_names = [ 'player_name', 'team_abbreviation', 'age', 'player_height', 'player_weight', 'college', 'country', 'draft_year', 'draft_round', 'draft_number', 'gp', 'pts', 'reb', 'ast', 'net_rating', 'oreb_pct', 'dreb_pct', 'usg_pct', 'ts_pct', 'ast_pct', 'season', 'data_pts', 'data_age', 'data_weight','data_height','data_gp']\n",
    "seasons = pd.read_csv('all_seasons.csv', names = col_names)\n",
    "\n",
    "\n",
    "# In[156]:\n",
    "\n",
    "\n",
    "seasons.head()\n",
    "\n",
    "\n",
    "# In[157]:\n",
    "\n",
    "\n",
    "#player points\n",
    "with open('all_seasons.csv', 'r') as read_obj: \n",
    "    next(read_obj)\n",
    "    with open ('new_seasons.csv', 'w', newline='') as write_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        csv_writer = writer(write_obj)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            if float(row[12]) > 0.0 and float(row[12]) < 10.0:\n",
    "                row.append(\"1\")\n",
    "            if float(row[12]) > 10.0 and float(row[12]) < 20.0:\n",
    "                row.append(\"2\") \n",
    "            if float(row[12]) > 20.0 and float(row[12]) < 30.0:\n",
    "                row.append('3') \n",
    "            if float(row[12]) > 30.0 and float(row[12]) < 40.0:\n",
    "                row.append('4') \n",
    "            #if float(row[12]) > 25.0 and float(row[12]) < 30.0:\n",
    "                #row.append('5')  \n",
    "            #if float(row[12]) > 30.0 and float(row[12]) < 40.0:\n",
    "                #row.append('6')  \n",
    "            csv_writer.writerow(row)\n",
    "            \n",
    "            \n",
    "new_pts = pd.read_csv('new_seasons.csv', header=None, names=col_names)\n",
    "new_pts.head()\n",
    "#print(new_pts)\n",
    "\n",
    "\n",
    "# In[158]:\n",
    "\n",
    "\n",
    "print(new_pts['data_pts'].describe())\n",
    "#Every 6th points\n",
    "\n",
    "\n",
    "# In[159]:\n",
    "\n",
    "\n",
    "#player_age\n",
    "with open('new_seasons.csv', 'r') as read_obj: \n",
    "    next(read_obj)\n",
    "    with open ('new_seasons1.csv', 'w', newline='') as write_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        csv_writer = writer(write_obj)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            if float(row[3]) > 18.0 and float(row[3]) < 23.0:\n",
    "                row.append(\"1\")\n",
    "            if float(row[3]) > 24.0 and float(row[3]) < 29.0:\n",
    "                row.append(\"2\") \n",
    "            if float(row[3]) > 30.0 and float(row[3]) < 35.0:\n",
    "                row.append('3') \n",
    "            if float(row[3]) > 36.0 and float(row[3]) < 41.0:\n",
    "                row.append('4') \n",
    "            if float(row[3]) > 42.0 and float(row[3]) < 47.0:\n",
    "                row.append('5')  \n",
    "            csv_writer.writerow(row)\n",
    "new_pts1 = pd.read_csv('new_seasons1.csv', header=None, names=col_names)\n",
    "new_pts1.head()            \n",
    "\n",
    "\n",
    "# In[160]:\n",
    "\n",
    "\n",
    "print(new_pts1['data_age'].describe())\n",
    "\n",
    "\n",
    "# In[161]:\n",
    "\n",
    "\n",
    "#player_weight\n",
    "with open('new_seasons1.csv', 'r') as read_obj: \n",
    "    next(read_obj)\n",
    "    with open ('new_seasons2.csv', 'w', newline='') as write_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        csv_writer = writer(write_obj)\n",
    "        for row in csv_reader:\n",
    "            if float(row[5]) > 60.0 and float(row[5]) < 80.0:\n",
    "                row.append(\"1\")\n",
    "            if float(row[5]) > 70.0 and float(row[5]) < 110.0:\n",
    "                row.append(\"2\")\n",
    "            if float(row[5]) > 110.0 and float(row[5]) < 130.0:\n",
    "                row.append(\"2\")\n",
    "            if float(row[5]) > 130.0 and float(row[5]) < 150.0:\n",
    "                row.append('3')\n",
    "            if float(row[5]) > 150.0 and float(row[5]) < 164.0:\n",
    "                row.append('4')\n",
    "            csv_writer.writerow(row)\n",
    "new_pts2 = pd.read_csv('new_seasons2.csv', header=None, names=col_names)\n",
    "new_pts2.head()\n",
    "\n",
    "\n",
    "# In[162]:\n",
    "print(row[4])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[163]:\n",
    "\n",
    "\n",
    "#player_height\n",
    "with open('new_seasons2.csv', 'r') as read_obj: \n",
    "    next(read_obj)\n",
    "    with open ('new_seasons3.csv', 'w', newline='') as write_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        csv_writer = writer(write_obj)\n",
    "        for row in csv_reader:\n",
    "            if float(row[4]) > 160.0 and float(row[4]) < 189.0:\n",
    "                row.append(\"1\")\n",
    "            if float(row[4]) > 190.0 and float(row[4]) < 200.0:\n",
    "                row.append(\"2\") \n",
    "            if float(row[4]) > 201.0 and float(row[4]) < 208.0:\n",
    "                row.append('3') \n",
    "            if float(row[4]) > 209.0 and float(row[4]) < 217.0:\n",
    "                row.append('4') \n",
    "            if float(row[4]) > 217.0 and float(row[4]) < 232.0:\n",
    "                row.append('5')  \n",
    "            csv_writer.writerow(row)\n",
    "new_pts3 = pd.read_csv('new_seasons3.csv', header=None, names=col_names)\n",
    "new_pts3.head()\n",
    "\n",
    "\n",
    "# In[164]:\n",
    "with open('new_seasons3.csv', 'r') as read_obj: \n",
    "    next(read_obj)\n",
    "    with open ('new_seasons4.csv', 'w', newline='') as write_obj:\n",
    "        csv_reader = reader(read_obj)\n",
    "        csv_writer = writer(write_obj)\n",
    "        for row in csv_reader:\n",
    "            if float(row[11]) > 0.0 and float(row[11]) < 40.0:\n",
    "                row.append(\"1\")\n",
    "            if float(row[11]) > 40.0 and float(row[11]) < 60.0:\n",
    "                row.append(\"2\")\n",
    "            if float(row[11]) > 60.0 and float(row[11]) < 90.0:\n",
    "                row.append('3')\n",
    "            csv_writer.writerow(row)\n",
    "new_pts4 = pd.read_csv('new_seasons4.csv', header=None, names=col_names)\n",
    "new_pts4.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_pts4['age'].fillna(new_pts4['age'].mode()[0], inplace = True)\n",
    "new_pts4['player_height'].fillna(new_pts4['player_height'].mode()[0], inplace = True)\n",
    "new_pts4['player_weight'].fillna(new_pts4['player_weight'].mode()[0], inplace = True)\n",
    "new_pts4['draft_year'].fillna(new_pts4['draft_year'].mode()[0], inplace = True)\n",
    "new_pts4['draft_round'].fillna(new_pts4['season'].mode()[0], inplace = True)\n",
    "new_pts4['season'].fillna(new_pts4['season'].mode()[0], inplace = True)\n",
    "new_pts4['data_pts'].fillna(new_pts4['data_pts'].mode()[0], inplace = True)\n",
    "new_pts4['data_age'].fillna(new_pts4['data_age'].mode()[0], inplace = True)\n",
    "new_pts4['data_weight'].fillna(new_pts4['data_weight'].mode()[0], inplace = True)\n",
    "new_pts4['data_height'].fillna(new_pts4['data_height'].mode()[0], inplace = True)\n",
    "new_pts4['data_gp'].fillna(new_pts4['data_gp'].mode()[0], inplace = True)\n",
    "new_pts4.isnull().sum()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[266]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "new_pts4['season'] = lb_make.fit_transform(new_pts4['season'])\n",
    "new_pts4['draft_round'] = lb_make.fit_transform(new_pts4['draft_round'])\n",
    "new_pts4['draft_year'] = lb_make.fit_transform(new_pts4['draft_year'])\n",
    "new_pts4['team_abbreviation'] = lb_make.fit_transform(new_pts4['team_abbreviation'])\n",
    "\n",
    "\n",
    "# In[267]:\n",
    "\n",
    "\n",
    "#new_pts = seasons.drop(seasons.index[0])\n",
    "new_pts4.head()\n",
    "\n",
    "\n",
    "# In[167]:\n",
    "\n",
    "\n",
    "#seasons[['data']].describe()\n",
    "\n",
    "\n",
    "# In[295]:\n",
    "\n",
    "\n",
    "#removing season and team abbreviation draft year and draft round\n",
    "features = ['age','player_height', 'team_abbreviation','draft_year', 'season']\n",
    "x = new_pts4.loc[:, features]\n",
    "y = new_pts4.loc[:,['data_pts','data_gp']]\n",
    "\n",
    "\n",
    "# In[296]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "# In[297]:\n",
    "\n",
    "\n",
    "print(type(X_train), X_train.size, X_train.shape)\n",
    "print(type(Y_train), Y_train.size, Y_train.shape)\n",
    "print(type(X_test), X_test.size, X_test.shape)\n",
    "print(type(Y_test), Y_test.size, Y_test.shape)\n",
    "\n",
    "\n",
    "# In[298]:\n",
    "\n",
    "\n",
    "tf.convert_to_tensor(Y_train, np.float)\n",
    "tf.convert_to_tensor(X_train, np.float)\n",
    "\n",
    "\n",
    "# In[299]:\n",
    "\n",
    "\n",
    "print(type(X_train), X_train.size, X_train.shape)\n",
    "print(type(Y_train), Y_train.size, Y_train.shape)\n",
    "print(type(X_test), X_test.size, X_test.shape)\n",
    "print(type(Y_test), Y_test.size, Y_test.shape)\n",
    "\n",
    "\n",
    "# In[306]:\n",
    "\n",
    "\n",
    "X_train=np.asarray(X_train).astype(np.float32)\n",
    "X_test=np.asarray(X_test).astype(np.float32)\n",
    "Y_train=np.asarray(Y_train).astype(np.float32)\n",
    "Y_test=np.asarray(Y_test).astype(np.float32)\n",
    "\n",
    "\n",
    "# In[307]:\n",
    "\n",
    "\n",
    "print(type(X_train), X_train.size, X_train.shape)\n",
    "print(type(Y_train), Y_train.size, Y_train.shape)\n",
    "print(type(X_test), X_test.size, X_test.shape)\n",
    "print(type(Y_test), Y_test.size, Y_test.shape)\n",
    "\n",
    "\n",
    "# In[308]:\n",
    "\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(27, input_dim=5, activation='relu'))\n",
    "model.add(Dense(13, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# In[309]:\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# In[310]:\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# In[311]:\n",
    "\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=300, batch_size =30)\n",
    "\n",
    "\n",
    "# In[264]:\n",
    "\n",
    "\n",
    "model.predict_classes(X_test)\n",
    "\n",
    "\n",
    "# In[265]:\n",
    "\n",
    "\n",
    "model.evaluate(X_test, Y_test)[1]\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
